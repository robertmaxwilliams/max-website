
# Current Stuff

## Undergraduate at UofL

I'm studying Computer Engineering and Computer Science, with a Math minor.  While I tend to learn
more in my own projects than in curriculum, I also know I wouldn't be able to do it without the
scheduled and mandated learning environment filled with skilled professors and deadlines.

## Research Project 

I'm currently working on the topic of "Adversarial Examples Transfer from Recurrent Neural Networks
to Finite State Automata". Recurrent Neural Networks (RNNs) can be made to misclassify a sequence
with very small input perturbations, analogous to 
[adversarial examples for image classification](https://blog.openai.com/adversarial-example-research/).
Some adversarial examples also 
[transfer to humans](https://arxiv.org/abs/1802.08195). From this, I make the hypothesis that given
some real-world or simulated system of any kind that performs a task, a neural network proxy can be
made to approximate it and that, correctly crafted, inputs that cause a failure of the proxy should
have a similar effect on the real system. Exactly what kind of systems this is possible for and how
to go about making proxies that give useful adversarial examples is the challenge here.

I'm working on an RNN that emulates a spring-mass system, and seeing if the standard way of creating
adversarial input will discover how to make a sine wave at resonance to maximize displacement. This
is starting to sound like a poor substitute for reinforcement learning, I'll have to consider where
that lies.

# Past Stuff

## MAST-ML

Summer of 2019, [Luke Miles](https://lukemiles.org/) and I worked for Dr. Finkel at the University
of Kentucky, on the [MAST-ML](https://github.com/uw-cmg/MAST-ML)

